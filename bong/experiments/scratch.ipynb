{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39309/945712042.py:6: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-5w5vab6u because the default path (/teamspace/studios/this_studio/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "from typing import Any, Callable, Sequence\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import jax\n",
    "import jax.random as jr\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax.flatten_util import ravel_pytree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from flax import linen as nn\n",
    "\n",
    "\n",
    "from bong.util import run_rebayes_algorithm, gaussian_kl_div, MLP\n",
    "from bong.src import bbb, blr, bog, bong, experiment_utils\n",
    "#from bong.agents import AGENT_NAMES\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nll', 'nlpd', 'nlpd_baseline_gauss', 'nlpd_baseline_linreg']\n",
      "dict_keys(['debug-00', 'debug-01'])\n",
      "{'debug-00': {'metric': 'nlpd', 'vals': array([6.255096 , 4.3706784, 4.6200023, 3.751373 , 2.6322014, 2.5394378,\n",
      "       2.259621 , 2.3075478, 2.2689984, 2.2576783, 2.1363552, 1.9710131,\n",
      "       2.08165  , 2.0913718, 2.0830104, 2.0527666, 2.0617738, 1.9780068,\n",
      "       1.9953151, 1.8947744, 1.9055114, 1.9346265, 1.8598626, 1.9305094,\n",
      "       1.9786673, 1.8318822, 1.8133383, 1.801294 , 1.8363414, 1.800544 ,\n",
      "       1.7768335, 1.8018401, 1.7829422, 1.7713866, 1.7693111, 1.7722384,\n",
      "       1.7130556, 1.7340417, 1.7578032, 1.7166048, 1.7229229, 1.7297478,\n",
      "       1.7124336, 1.6998836, 1.6975358, 1.6697313, 1.6553525, 1.6707144,\n",
      "       1.6634917, 1.6443434]), 'valid_len': 50, 'agent_name': 'bong-fc-EF1-MC10', 'agent_full_name': 'bong-fc-R0-Lin0-EF1-MC10-I1-LR0_0', 'model_name': 'mlp_10_1[P=121]', 'data_name': 'reg-D10-mlp_20_20_1', 'elapsed': 2.6643183309997767}, 'debug-01': {'metric': 'nlpd', 'vals': array([6.255096 , 5.9583435, 6.943332 , 5.1859093, 5.2105513, 4.7680125,\n",
      "       4.7894216, 4.690409 , 4.614992 , 4.619199 , 3.9681764, 4.414244 ,\n",
      "       4.2247815, 4.315339 , 4.1552005, 5.0605865, 4.274377 , 4.3401613,\n",
      "       4.7064996, 4.6396074, 5.1547103, 4.364287 , 4.0754766, 5.0914497,\n",
      "       4.2959037, 4.0418925, 4.5777354, 4.565154 , 4.2053432, 4.3893466,\n",
      "       4.509323 , 4.7033234, 4.538322 , 4.170109 , 3.8668497, 4.186033 ,\n",
      "       4.108563 , 4.4698353, 4.0512047, 3.8927321, 3.897396 , 3.8299236,\n",
      "       4.02956  , 3.8599317, 3.8908527, 3.583352 , 3.7721548, 3.9862869,\n",
      "       3.7882493, 3.6298044]), 'valid_len': 50, 'agent_name': 'bong-fc-lin', 'agent_full_name': 'bong-fc-R0-Lin1-EF99-MC99-I1-LR0_0', 'model_name': 'mlp_10_1[P=121]', 'data_name': 'reg-D10-mlp_20_20_1', 'elapsed': 1.481768509000176}}\n"
     ]
    }
   ],
   "source": [
    "from job_utils import *\n",
    "dir = '/teamspace/studios/this_studio/jobs/debug' \n",
    "\n",
    "metrics = extract_metrics_from_files(dir, exclude_val=True, jobs_file=\"jobs.csv\")\n",
    "print(metrics)\n",
    "\n",
    "metric = 'nlpd'\n",
    "results = extract_results_from_files(dir,  metric, jobs_file=\"jobs.csv\")\n",
    "print(results.keys())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['debug-00', 'debug-01'])\n",
      "{'debug-00': {'metric': 'nlpd_baseline_gauss', 'vals': array([1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542]), 'valid_len': 50, 'agent_name': 'bong-fc-EF1-MC10', 'agent_full_name': 'bong-fc-R0-Lin0-EF1-MC10-I1-LR0_0', 'model_name': 'mlp_10_1[P=121]', 'data_name': 'reg-D10-mlp_20_20_1', 'elapsed': 2.6643183309997767}, 'debug-01': {'metric': 'nlpd_baseline_gauss', 'vals': array([1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542]), 'valid_len': 50, 'agent_name': 'bong-fc-lin', 'agent_full_name': 'bong-fc-R0-Lin1-EF99-MC99-I1-LR0_0', 'model_name': 'mlp_10_1[P=121]', 'data_name': 'reg-D10-mlp_20_20_1', 'elapsed': 1.481768509000176}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metric = 'nlpd_baseline_gauss'\n",
    "results_baseline = extract_results_from_files(dir,  metric, jobs_file=\"jobs.csv\")\n",
    "print(results_baseline.keys())\n",
    "print(results_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['metric', 'vals', 'valid_len', 'agent_name', 'agent_full_name', 'model_name', 'data_name', 'elapsed'])\n",
      "{'metric': 'nlpd_baseline_gauss', 'vals': array([1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542]), 'valid_len': 50, 'agent_name': 'bong-fc-EF1-MC10', 'agent_full_name': 'bong-fc-R0-Lin0-EF1-MC10-I1-LR0_0', 'model_name': 'mlp_10_1[P=121]', 'data_name': 'reg-D10-mlp_20_20_1', 'elapsed': 2.6643183309997767}\n"
     ]
    }
   ],
   "source": [
    "jobnames = list(results_baseline.keys())\n",
    "jobname = jobnames[0]\n",
    "res_baseline = results_baseline[jobname]\n",
    "print(res_baseline.keys())\n",
    "print(res_baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['debug-00', 'debug-01', 'job_baseline_gauss'])\n",
      "{'debug-00': {'metric': 'nlpd', 'vals': array([6.255096 , 4.3706784, 4.6200023, 3.751373 , 2.6322014, 2.5394378,\n",
      "       2.259621 , 2.3075478, 2.2689984, 2.2576783, 2.1363552, 1.9710131,\n",
      "       2.08165  , 2.0913718, 2.0830104, 2.0527666, 2.0617738, 1.9780068,\n",
      "       1.9953151, 1.8947744, 1.9055114, 1.9346265, 1.8598626, 1.9305094,\n",
      "       1.9786673, 1.8318822, 1.8133383, 1.801294 , 1.8363414, 1.800544 ,\n",
      "       1.7768335, 1.8018401, 1.7829422, 1.7713866, 1.7693111, 1.7722384,\n",
      "       1.7130556, 1.7340417, 1.7578032, 1.7166048, 1.7229229, 1.7297478,\n",
      "       1.7124336, 1.6998836, 1.6975358, 1.6697313, 1.6553525, 1.6707144,\n",
      "       1.6634917, 1.6443434]), 'valid_len': 50, 'agent_name': 'bong-fc-EF1-MC10', 'agent_full_name': 'bong-fc-R0-Lin0-EF1-MC10-I1-LR0_0', 'model_name': 'mlp_10_1[P=121]', 'data_name': 'reg-D10-mlp_20_20_1', 'elapsed': 2.6643183309997767}, 'debug-01': {'metric': 'nlpd', 'vals': array([6.255096 , 5.9583435, 6.943332 , 5.1859093, 5.2105513, 4.7680125,\n",
      "       4.7894216, 4.690409 , 4.614992 , 4.619199 , 3.9681764, 4.414244 ,\n",
      "       4.2247815, 4.315339 , 4.1552005, 5.0605865, 4.274377 , 4.3401613,\n",
      "       4.7064996, 4.6396074, 5.1547103, 4.364287 , 4.0754766, 5.0914497,\n",
      "       4.2959037, 4.0418925, 4.5777354, 4.565154 , 4.2053432, 4.3893466,\n",
      "       4.509323 , 4.7033234, 4.538322 , 4.170109 , 3.8668497, 4.186033 ,\n",
      "       4.108563 , 4.4698353, 4.0512047, 3.8927321, 3.897396 , 3.8299236,\n",
      "       4.02956  , 3.8599317, 3.8908527, 3.583352 , 3.7721548, 3.9862869,\n",
      "       3.7882493, 3.6298044]), 'valid_len': 50, 'agent_name': 'bong-fc-lin', 'agent_full_name': 'bong-fc-R0-Lin1-EF99-MC99-I1-LR0_0', 'model_name': 'mlp_10_1[P=121]', 'data_name': 'reg-D10-mlp_20_20_1', 'elapsed': 1.481768509000176}, 'job_baseline_gauss': {'metric': 'nlpd', 'vals': array([1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542, 1.4662542,\n",
      "       1.4662542, 1.4662542]), 'valid_len': 50, 'agent_name': 'baseline_gauss', 'agent_full_name': 'baseline_gauss', 'model_name': 'mlp_10_1[P=121]', 'data_name': 'reg-D10-mlp_20_20_1', 'elapsed': 2.6643183309997767}}\n"
     ]
    }
   ],
   "source": [
    "baseline_dict = res_baseline\n",
    "baseline_dict['agent_name'] = 'baseline-gauss'\n",
    "baseline_dict['agent_full_name'] = 'baseline'\n",
    "baseline_dict['metric'] = 'nlpd'\n",
    "baseline_dict['elapsed'] = 0\n",
    "\n",
    "results2 = results.copy()\n",
    "results2['job_baseline_gauss'] = baseline_dict\n",
    "print(results2.keys())\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Data parameters\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"reg\") \n",
    "parser.add_argument(\"--data_dim\", type=int, default=10)\n",
    "parser.add_argument(\"--data_key\", type=int, default=0)\n",
    "parser.add_argument(\"--dgp_type\", type=str, default=\"lin\") # or mlp\n",
    "parser.add_argument(\"--dgp_str\", type=str, default=\"\") # 20_20_1 \n",
    "parser.add_argument(\"--emission_noise\", type=float, default=1.0)\n",
    "parser.add_argument(\"--ntrain\", type=int, default=500)\n",
    "parser.add_argument(\"--nval\", type=int, default=500)\n",
    "parser.add_argument(\"--ntest\", type=int, default=1000)\n",
    "parser.add_argument(\"--add_ones\", type=int, default=0)\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "#parser.add_argument(\"--agent\", type=str, default=\"bong_fc\", choices=AGENT_NAMES)\n",
    "parser.add_argument(\"--algo\", type=str, default=\"bong\")\n",
    "parser.add_argument(\"--param\", type=str, default=\"fc\")\n",
    "parser.add_argument(\"--agent_key\", type=int, default=0)\n",
    "parser.add_argument(\"--lr\", type=float, default=0.01)\n",
    "parser.add_argument(\"--niter\", type=int, default=10) \n",
    "parser.add_argument(\"--nsample\", type=int, default=100) \n",
    "parser.add_argument(\"--ef\", type=int, default=1)\n",
    "parser.add_argument(\"--lin\", type=int, default=0)\n",
    "parser.add_argument(\"--rank\", type=int, default=10)\n",
    "parser.add_argument(\"--model_type\", type=str, default=\"lin\") # or mlp\n",
    "parser.add_argument(\"--model_str\", type=str, default=\"1\")\n",
    "parser.add_argument(\"--use_bias\", type=int, default=1) \n",
    "parser.add_argument(\"--init_var\", type=float, default=1.0)\n",
    "parser.add_argument(\"--algo_key\", type=int, default=0)\n",
    "\n",
    "# results\n",
    "parser.add_argument(\"--dir\", type=str, default=\"\", help=\"directory to store results\") \n",
    "parser.add_argument(\"--debug\", type=bool, default=False)\n",
    "\n",
    "args = parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from bong.agents import make_agent_constructor\n",
    "from datasets import make_dataset\n",
    "from models import make_model\n",
    "from run_job import run_agent\n",
    "\n",
    "data = make_dataset(args)\n",
    "model = make_model(args, data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RebayesAlgorithm(init=<function fg_bong.__new__.<locals>.init_fn at 0x7f6e062ae560>, predict=<function fg_bong.__new__.<locals>.pred_fn at 0x7f6e062ae0e0>, update=<function fg_bong.__new__.<locals>.update_fn at 0x7f6e062adbd0>, sample=<function sample_fg_bong at 0x7f6e15e22950>, name='bong-fc-EF1-MC100', full_name='bong-fc-R0-Lin0-EF1-MC100-I1-LR0_0')\n"
     ]
    }
   ],
   "source": [
    "#name = f'{args.algo}_{args.param}' # eg bong-fc_mom, must match keys of AGENT_DICT\n",
    "#constructor = AGENT_DICT[name]['constructor']\n",
    "constructor = make_agent_constructor(args.algo, args.param)\n",
    "agent = constructor(\n",
    "                    **model['model_kwargs'],\n",
    "                    agent_key = args.agent_key,\n",
    "                    learning_rate = args.lr,\n",
    "                    num_iter = args.niter,\n",
    "                    num_samples = args.nsample,\n",
    "                    linplugin = args.lin,\n",
    "                    empirical_fisher = args.ef,\n",
    "                    rank = args.rank\n",
    "                )\n",
    "print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bong-fc-EF1-MC100 + lin_1[P=10] on reg-D10-lin_1\n",
      "Using GPU of type:  None\n",
      "Time 1.72s\n",
      "KL: 2.1543\n",
      "Test NLL: 1.4174,  NLPD: 1.4290\n",
      "Val NLL 1.4390,  NLPD: 1.4554\n"
     ]
    }
   ],
   "source": [
    "key = jr.PRNGKey(args.agent_key)\n",
    "results, elapsed, summary = run_agent(key, agent, data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['nll', 'nlpd', 'nll_val', 'nlpd_val', 'kldiv', 'kldiv_val', 'nlpd_baseline_gauss', 'nlpd_baseline_linreg'])\n",
      "(500,)\n",
      "1.5176852\n"
     ]
    }
   ],
   "source": [
    "print(results.keys())\n",
    "res = results['nlpd']\n",
    "print(res.shape)\n",
    "\n",
    "res = results['nlpd_baseline_gauss']\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobname</th>\n",
       "      <th>algo</th>\n",
       "      <th>param</th>\n",
       "      <th>lin</th>\n",
       "      <th>dlr_rank</th>\n",
       "      <th>ef</th>\n",
       "      <th>nsample</th>\n",
       "      <th>niter</th>\n",
       "      <th>lr</th>\n",
       "      <th>nlpd_te_final</th>\n",
       "      <th>nlpd_te_mid</th>\n",
       "      <th>nlpd_val_final</th>\n",
       "      <th>nlpd_val_mid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sweep3-01</td>\n",
       "      <td>bog</td>\n",
       "      <td>fc</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.539317e+00</td>\n",
       "      <td>3.269134e+00</td>\n",
       "      <td>2.526866e+00</td>\n",
       "      <td>2.753690e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sweep3-03</td>\n",
       "      <td>bog</td>\n",
       "      <td>fc</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.805015e+00</td>\n",
       "      <td>2.016883e+00</td>\n",
       "      <td>1.855236e+00</td>\n",
       "      <td>1.803196e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sweep3-05</td>\n",
       "      <td>bog</td>\n",
       "      <td>fc</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>1.712355e+00</td>\n",
       "      <td>2.092516e+00</td>\n",
       "      <td>1.773460e+00</td>\n",
       "      <td>1.962286e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sweep3-07</td>\n",
       "      <td>bog</td>\n",
       "      <td>fc</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sweep3-09</td>\n",
       "      <td>bog</td>\n",
       "      <td>fc</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sweep3-11</td>\n",
       "      <td>bog</td>\n",
       "      <td>fc</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sweep3-13</td>\n",
       "      <td>bog</td>\n",
       "      <td>fc</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "      <td>1.000000e+20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      jobname algo param  lin  dlr_rank  ef  nsample  niter      lr  \\\n",
       "1   sweep3-01  bog    fc    0        99   1      100     99  0.0001   \n",
       "3   sweep3-03  bog    fc    0        99   1      100     99  0.0005   \n",
       "5   sweep3-05  bog    fc    0        99   1      100     99  0.0010   \n",
       "7   sweep3-07  bog    fc    0        99   1      100     99  0.0050   \n",
       "9   sweep3-09  bog    fc    0        99   1      100     99  0.0100   \n",
       "11  sweep3-11  bog    fc    0        99   1      100     99  0.0500   \n",
       "13  sweep3-13  bog    fc    0        99   1      100     99  0.1000   \n",
       "\n",
       "    nlpd_te_final   nlpd_te_mid  nlpd_val_final  nlpd_val_mid  \n",
       "1    2.539317e+00  3.269134e+00    2.526866e+00  2.753690e+00  \n",
       "3    1.805015e+00  2.016883e+00    1.855236e+00  1.803196e+00  \n",
       "5    1.712355e+00  2.092516e+00    1.773460e+00  1.962286e+00  \n",
       "7    1.000000e+20  1.000000e+20    1.000000e+20  1.000000e+20  \n",
       "9    1.000000e+20  1.000000e+20    1.000000e+20  1.000000e+20  \n",
       "11   1.000000e+20  1.000000e+20    1.000000e+20  1.000000e+20  \n",
       "13   1.000000e+20  1.000000e+20    1.000000e+20  1.000000e+20  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir = '/teamspace/studios/this_studio/jobs/sweep3'\n",
    "df = pd.read_csv(f'{results_dir}/jobs_with_eval.csv')\n",
    "\n",
    "#condition = (df['minscore'] != df[args.metric])\n",
    "condition = (df['lin']==1) | (df['ef']==0)\n",
    "indices_to_drop = df[condition].index\n",
    "df_filtered = df.drop(indices_to_drop)\n",
    "\n",
    "df_filtered.head(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121, 481, 841, 1201]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#x = [11*n + (n+1)*1 for n in [10,20,30,40,50]]\n",
    "x = [11*n + (n+1)*1 for n in [10,40,70,100]]\n",
    "\n",
    "#x = [11*n + (n+1)*1 for n in [10, 500,1000, 2000, 5000]] # DLR\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gaussianprocess.org/gpml/data/\n",
    "\n",
    "def make_sarcos_data(ntrain, nval, ntest):\n",
    "    import scipy.io\n",
    "    folder = '/teamspace/studios/this_studio/bong/bong/data'\n",
    "    print(folder)\n",
    "\n",
    "    mat_data = scipy.io.loadmat(f'{folder}/sarcos_inv.mat') # (44484, 28)\n",
    "    data_train = mat_data['sarcos_inv']\n",
    "    max_ntrain = data_train.shape[0] \n",
    "    assert ntrain < max_ntrain\n",
    "    idx_tr = np.arange(0, ntrain)\n",
    "    X_tr = data_train[idx_tr, :21]\n",
    "    Y_tr = data_train[idx_tr, 21] # column 22\n",
    "\n",
    "    idx_val = np.arange(ntrain, ntrain+nval)\n",
    "    X_val = data_train[idx_val, :21]\n",
    "    Y_val = data_train[idx_val, 21] # column 22\n",
    "\n",
    "    mat_data = scipy.io.loadmat(f'{folder}/sarcos_inv_test.mat') # (4449, 28)\n",
    "    data_test = mat_data['sarcos_inv_test']\n",
    "    max_ntest = data_test.shape[0] \n",
    "    assert ntest < max_ntest\n",
    "    if ntest == 0: ntest = max_ntest # Use full test set\n",
    "    idx_te = np.arange(0, ntest)\n",
    "    X_te = data_test[idx_te, :21]\n",
    "    Y_te = data_test[idx_te, 21] # column 22\n",
    "\n",
    "    name = 'sarcos'\n",
    "    # We return X_tr etc for use by rebayes, as well as X_train (full data) for debugging\n",
    "    data = {\n",
    "        'X_tr': X_tr, 'Y_tr': Y_tr, 'X_val': X_val, 'Y_val': Y_val, 'X_te': X_te, 'Y_te': Y_te, 'name': name, \n",
    "        'X_train': data_train[:, :21], 'Y_train': data_train[:, 22],\n",
    "        'X_test': data_test[:, :21], 'Y_test': data_test[:, 22],\n",
    "        'sarcos': data_train[:, :22]\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sarcos = pd.read_csv('sarcos_inv.csv', header = None).values\n",
    "data = make_sarcos_data(ntrain=1000, nval=1000, ntest=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE=22.68, SMSE=0.10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# https://gaussianprocess.org/gpml/chapters/RW2.pdf\n",
    "# . The inputs were linearly rescaled to have zero mean and unit variance on the training set.\n",
    "# The outputs were centered so as to have zero mean on the training set.\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(data['X_train'])\n",
    "Xtrain, Xtest = scaler.transform(data['X_train']), scaler.transform(data['X_test'])\n",
    "ytrain, ytest = data['Y_train'], data['Y_test']\n",
    "mu_y, v_y = np.mean(ytrain), np.var(ytrain)\n",
    "ytrain, ytest = ytrain - mu_y, ytest - mu_y\n",
    "\n",
    "def calc_mse(prediction, Y):\n",
    "    mse = np.mean(np.square(prediction - Y))\n",
    "    return mse\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(Xtrain, ytrain)\n",
    "prediction = model.predict(Xtest)\n",
    "mse = calc_mse(prediction, ytest)\n",
    "\n",
    "#  It makes sense to normalize by the variance of the\n",
    "# targets of the test cases to obtain the standardized mean squared error (SMSE).\n",
    "# This causes the trivial method of guessing the mean of the training targets to SMSE\n",
    "# # have a SMSE of approximately 1.\n",
    "\n",
    "\n",
    "smse = mse / v_y\n",
    "print(f'MSE={mse:.2f}, SMSE={smse:.2f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE=22.68, SMSE=0.10\n"
     ]
    }
   ],
   "source": [
    "# We follow sec 2.5 of https://gaussianprocess.org/gpml/chapters/RW2.pdf\n",
    "# The inputs were linearly rescaled to have zero mean and unit variance on the training set.\n",
    "# The outputs were centered so as to have zero mean on the training set.\n",
    "# SMSE is the MSE / var(ytrain)\n",
    "\n",
    "def calc_mse(prediction, Y):\n",
    "    mse = jnp.mean(jnp.square(prediction - Y))\n",
    "    return mse\n",
    "\n",
    "def add_col_ones(X):\n",
    "    ones_column = jnp.ones((X.shape[0], 1))\n",
    "    return jnp.hstack((ones_column, X))\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(data['X_train'])\n",
    "Xtrain = add_col_ones(scaler.transform(data['X_train']))\n",
    "Xtest = add_col_ones(scaler.transform(data['X_test']))\n",
    "ytrain, ytest = data['Y_train'], data['Y_test']\n",
    "mu_y, v_y = jnp.mean(ytrain), jnp.var(ytrain)\n",
    "ytrain, ytest = ytrain - mu_y, ytest - mu_y\n",
    "\n",
    "params, residuals, rank, s = np.linalg.lstsq(Xtrain, ytrain, rcond=None)\n",
    "prediction = Xtest @ params \n",
    "mse = calc_mse(prediction, ytest)\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(Xtrain, ytrain)\n",
    "prediction = model.predict(Xtest)\n",
    "mse_sklearn = calc_mse(prediction, ytest)\n",
    "\n",
    "print(f'MSE(jax)={mse:.2f}, MSE(sklearn)={mse_sklearn:.2f}, SMSE={mse/v_y:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6768196 -1.7491357\n"
     ]
    }
   ],
   "source": [
    "gauss_log_likelihood = lambda mean, cov, y: \\\n",
    "    jax.scipy.stats.norm.logpdf(y, mean, jnp.sqrt(jnp.diag(cov))).sum()\n",
    "\n",
    "def nll_gauss(params, x, y):\n",
    "    mu_y, v_t, w = params\n",
    "    m = mu_y * jnp.eye(1)\n",
    "    c = v_y * jnp.eye(1)\n",
    "    return -gauss_log_likelihood(m, c, y)\n",
    "\n",
    "def nll_linreg(params, x, y):\n",
    "    mu_y, v_t, w = params\n",
    "    m = jnp.dot(w, x) * jnp.eye(1)\n",
    "    c = v_y * jnp.eye(1)\n",
    "    return -gauss_log_likelihood(m, c, y)\n",
    "\n",
    "\n",
    "def compute_regression_baselines(Xtrain, ytrain, Xtest, ytest):\n",
    "    mu_y, v_y = jnp.mean(ytrain), jnp.var(ytrain)\n",
    "    #  model = sklearn.linear_model.LinearRegression() \n",
    "    w, residuals, rank, s = np.linalg.lstsq(Xtrain, ytrain, rcond=None) # model.fit(Xtrain, ytrain)\n",
    "    #prediction = Xtest @ w # prediction = model.predict(Xtest)\n",
    "    params = (mu_y, v_y, w)\n",
    "\n",
    "    nll_te_gauss = jnp.mean(jax.vmap(nll_baseline, (None, 0, 0))(params, Xtest, ytest))\n",
    "    nll_te_linreg = jnp.mean(jax.vmap(nll_linreg, (None, 0, 0))(params, Xtest, ytest))\n",
    "    return nll_te_gauss, nll_te_linreg\n",
    "\n",
    "\n",
    "\n",
    "nll_te_gauss, nll_te_linreg = compute_regression_baselines(Xtrain, ytrain, Xtest, ytest)\n",
    "msll = nll_te_linreg - nll_te_gauss\n",
    "print(nll_te_linreg, msll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4449\n",
      "(50,)\n",
      "16.766759879376583\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#https://github.com/JohDonald/SARCOS-problem/blob/main/SARCOS_Problem_ML.ipynb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "sarcos = data['sarcos']\n",
    "xt_, xtst_, yt, ytst = train_test_split(sarcos[:,:-1], sarcos[:,-1], train_size=0.9, random_state=101)\n",
    "\n",
    "ntest = ytst.shape[0]\n",
    "print(ntest)\n",
    "ntest = 50 # following notebook\n",
    "xtst_, ytst = xtst_[:ntest], ytst[:ntest]\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(xt_)\n",
    "xt, xtst = scaler.transform(xt_), scaler.transform(xtst_)\n",
    "\n",
    "def calc_mse(Prediction, Y):\n",
    "    mse = np.mean(np.square(Prediction - Y))\n",
    "    return mse\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(xt,yt)\n",
    "prediction = model.predict(xtst)\n",
    "print(prediction.shape)\n",
    "print(calc_mse(prediction, ytst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-13/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-13/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-13/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-10/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-10/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-10/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-02/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-02/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-02/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-00/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-00/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-00/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-15/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-15/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-15/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-41/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-41/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-41/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-18/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-18/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-18/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-44/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-44/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-44/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-27/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-27/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-27/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-17/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-17/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-17/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-08/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-08/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-08/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-31/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-31/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-31/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-23/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-23/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-23/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-20/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-20/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-20/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-16/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-16/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-16/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-47/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-47/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-47/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-12/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-12/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-12/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-45/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-45/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-45/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-33/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-33/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-33/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-07/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-07/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-07/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-21/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-21/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-21/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-04/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-04/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-04/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-30/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-30/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-30/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-38/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-38/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-38/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-37/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-37/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-37/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-01/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-01/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-01/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-25/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-25/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-25/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-36/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-36/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-36/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-24/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-24/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-24/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-11/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-11/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-11/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-09/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-09/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-09/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-05/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-05/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-05/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-22/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-22/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-22/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-03/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-03/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-03/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-06/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-06/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-06/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-35/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-35/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-35/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-43/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-43/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-43/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-26/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-26/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-26/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-42/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-42/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-42/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-14/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-14/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-14/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-39/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-39/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-39/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-32/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-32/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-32/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-34/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-34/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-34/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-19/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-19/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-19/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-46/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-46/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-46/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-40/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-40/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-40/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-29/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-29/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-29/work\n",
      "\n",
      " Creating /teamspace/studios/this_studio/jobs/expt_timing2-28/work\n",
      "sudo cp -r /teamspace/jobs/expt-timing2-28/work/*.* /teamspace/studios/this_studio/jobs/expt_timing2-28/work\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def list_subdirectories(directory):\n",
    "    return [name for name in os.listdir(directory)\n",
    "            if os.path.isdir(os.path.join(directory, name))]\n",
    "\n",
    "src = '/teamspace/jobs'\n",
    "dst = '/teamspace/studios/this_studio/jobs'\n",
    "dirs = list_subdirectories(src)\n",
    "for old_name in dirs:\n",
    "    parts = old_name.split('-')\n",
    "    num = parts[2]\n",
    "    new_name = f'expt_timing2-{num}'\n",
    "    dst_path = Path(dst, new_name, 'work')\n",
    "    print(f'\\n Creating {str(dst_path)}')\n",
    "    dst_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #cmd = f'mv {directory}/{old_name} {directory}/{new_name}'\n",
    "    cmd = f'sudo cp -r {src}/{old_name}/work/*.* {dst}/{new_name}/work'\n",
    "    print(cmd)\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_model\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrun_job\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_agent\n\u001b[0;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m make_model(args, data)\n",
      "File \u001b[0;32m~/bong/bong/experiments/datasets.py:45\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdgp_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mmake_data_reg_lin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdgp_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m         data \u001b[38;5;241m=\u001b[39m make_data_reg_mlp(args)\n",
      "File \u001b[0;32m~/bong/bong/experiments/datasets.py:149\u001b[0m, in \u001b[0;36mmake_data_reg_lin\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    147\u001b[0m key \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39mPRNGKey(args\u001b[38;5;241m.\u001b[39mdata_key)\n\u001b[1;32m    148\u001b[0m key0, key \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39msplit(key)\n\u001b[0;32m--> 149\u001b[0m theta \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_linear_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg-D\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mdata_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-lin_1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    152\u001b[0m key1, key2, key3, key \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39msplit(key, \u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/bong/bong/experiments/datasets.py:132\u001b[0m, in \u001b[0;36mgenerate_linear_model\u001b[0;34m(key, d)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_linear_model\u001b[39m(key, d):\n\u001b[0;32m--> 132\u001b[0m     key1, key2, key \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39msplit(\u001b[43mkeys\u001b[49m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    133\u001b[0m     theta \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39muniform(key1, (d,), minval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.\u001b[39m, maxval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m)\n\u001b[1;32m    134\u001b[0m     theta \u001b[38;5;241m=\u001b[39m theta \u001b[38;5;241m/\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(theta)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keys' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".bong_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
