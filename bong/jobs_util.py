from functools import partial
from typing import Any, Callable, Sequence
import argparse
from functools import partial
from pathlib import Path
import time
import re
import os
import json 
import pandas as pd


def list_subdirectories(directory):
    return [name for name in os.listdir(directory)
            if os.path.isdir(os.path.join(directory, name))]

def get_job_dir(parallel):
    # for lightning ai studio
    # https://lightning.ai/docs/overview/train-models/hyperparameter-sweeps
    # Results are generated by experiments/run_jobs
    if not(parallel):
            data_dir = '/teamspace/studios/this_studio/jobs' 
    else:
            data_dir = '/teamspace/jobs/' 
    return data_dir
 

def read_job_args(parallel):
    '''Read args.json for each run and return a dataframe'''
    jobdir = get_job_dir(parallel)
    subdirs = list_subdirectories(jobdir)

    dicts = []
    for jobname in subdirs:
        path = Path(jobdir, jobname, 'work', 'args.json')
        if not(path.exists()):
            print('skipping ', path)
            continue

        # the with context manager fails inside a notebook
        #with open(path, 'r') as file:
        # args_dict = json.load(file)
        
        file = open(path, 'r')
        args_dict = json.load(file)
        file.close()
        args_dict['job-name'] = jobname
        args_dict.pop('dir')
        args_dict.pop('filename')

        dicts.append(args_dict)

    jobs_df = pd.DataFrame(dicts)
    return jobs_df


def read_job_results(parallel):
    '''Read results.csv for each run and return a dict of dataframes'''
    jobdir = get_job_dir(parallel)
    subdirs = list_subdirectories(jobdir)
    results_dict = {} # map job name to dataframe of results
    for jobname in subdirs:
        path = Path(jobdir, jobname, 'work', 'results.csv')
        if not(path.exists()):
            print('skipping ', path)
            continue
        # the with context manager fails inside a notebook
        #with open(path, 'r') as file:
        # args_dict = json.load(file)
        file = open(path, 'r')
        df = pd.read_csv(path)
        file.close()
        results_dict[jobname] = df
    return results_dict


def get_job_name(args_df, query_dict):
    query_str = ' & '.join([f"{k} == {repr(v)}" for k, v in query_dict.items()])
    #query_str = ' & '.join([f"{k}=={v}" for k, v in query_dict.items()])
    filtered_df = args_df.query(query_str)
    if len(filtered_df) > 1:
        msg= f'query is not unique, {query_str} matches {len(filtered_df)}'
        raise Exception(msg)
    jobname = filtered_df['job-name'].item()
    return jobname

def get_job_args(args_df, jobname):
    my_args = args_df[ args_df['job-name']==jobname ]
    return my_args

def test_jobs():
    parallel = True
    args_df = read_job_args(parallel)
    print(args_df)

    query_dict = {'agent': 'fg-bong', 'learning_rate': 2.0, 'num_iter': 10}
    jobname = get_job_name(args_df, query_dict)
    print(jobname)

    results_dict = read_job_results(parallel)
    print(results_dict.keys())
    print(results_dict[jobname])